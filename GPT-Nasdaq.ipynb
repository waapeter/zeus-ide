{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGNyHBKAenClLguB4vwcnd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waapeter/zeus-ide/blob/master/GPT-Nasdaq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeOa9xrZSufv",
        "outputId": "e9cf1945-ea39-4235-d165-f19732225f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wrds in /usr/local/lib/python3.9/site-packages (3.1.6)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.9/site-packages (from wrds) (1.4.47)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from wrds) (2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from wrds) (1.10.1)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.9/site-packages (from wrds) (2.9.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from wrds) (1.24.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->wrds) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swig\n",
            "  Using cached swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "Installing collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/site-packages (8.12.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython) (0.18.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython) (4.5.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython) (0.6.2)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython) (5.9.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.9/site-packages (from ipython) (3.0.38)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython) (0.2.6)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython) (0.2.2)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython) (2.2.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m✨🍰✨ Everything looks OK!\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-gnu80utd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-gnu80utd\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 8a75a4bbb28f86f88ee2d4bd9a8c19cce444badb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5_hhnqo9/pyfolio_fa5b03868a98404cb461837e156435d5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/quantopian/pyfolio.git /tmp/pip-install-5_hhnqo9/pyfolio_fa5b03868a98404cb461837e156435d5\n",
            "  Resolved https://github.com/quantopian/pyfolio.git to commit 4b901f6d73aa02ceb6d04b7d83502e5c6f2e81aa\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5_hhnqo9/elegantrl_fee5b1b86965467cbad1a379e28c4c6a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5_hhnqo9/elegantrl_fee5b1b86965467cbad1a379e28c4c6a\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit b974a806e6235f59055c954418e54640fa549331\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: stockstats>=0.4.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.5.2)\n",
            "Requirement already satisfied: ray[default,tune]>=2.0.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.4.0)\n",
            "Requirement already satisfied: exchange_calendars==3.6.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.6.3)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.0.1)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.21.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.6)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.4.0)\n",
            "Requirement already satisfied: wrds>=3.1.6 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.1.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.24.3)\n",
            "Requirement already satisfied: jqdatasdk in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.11)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.2.2)\n",
            "Requirement already satisfied: alpaca_trade_api>=2.1.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: ccxt>=1.66.32 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.80)\n",
            "Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.13.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.2.18)\n",
            "Requirement already satisfied: stable-baselines3<2.0.0,>=1.6.2 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2023.3)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.2.0)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.3.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata==4.13.0->finrl==0.3.5) (3.15.0)\n",
            "Requirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.8.1)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (10.4)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.28.2)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.5.1)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.26.15)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.0)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.9.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (4.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from deprecation==2.1.0->alpaca_trade_api>=2.1.0->finrl==0.3.5) (23.1)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (2022.12.7)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (65.6.3)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (39.0.2)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas>=1.1.5->finrl==0.3.5) (2023.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (8.1.3)\n",
            "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (20.21.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.20.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (4.17.3)\n",
            "Requirement already satisfied: grpcio<=1.51.3,>=1.32.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.12.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.16.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (6.3.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.11.2)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.10.7)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.14)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/site-packages (from stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (2.9.6)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (1.4.47)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.16.0)\n",
            "Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (0.4.16)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (8.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.12.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (2.3.7)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.12.2)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.9/site-packages (from aiodns>=1.1.1->ccxt>=1.66.32->finrl==0.3.5) (4.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance->finrl==0.3.5) (2.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.9/site-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.10.0)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.20.0)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.9.5)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (11.525.112)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance->finrl==0.3.5) (0.5.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.5.0)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.15.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.18.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (3.0.38)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.1.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy<2->wrds>=3.1.6->finrl==0.3.5) (2.0.2)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.9/site-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.5) (3.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.14.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.91)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (0.38.4)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.26.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (16.0.2)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (3.5.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.9/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.6)\n",
            "Requirement already satisfied: pyglet>=1.4.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.0.5)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.3.5)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.19.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.11.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.1.3)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.9/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (2.21)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.59.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.1.2)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.2)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/site-packages (from sympy->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -U ipython\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"PK77D8FGOW608O2G0Y93\"\n",
        "API_SECRET = \"ppOn9d5ce1g9pipqfwAp16ruRdzjzvZOWflMapVp\"\n",
        "API_BASE_URL = 'https://paper-api.alpaca.markets'\n",
        "data_url = 'wss://data.alpaca.markets'"
      ],
      "metadata": {
        "id": "Cho9PhD8VHlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.config_tickers import NAS_100_TICKER\n",
        "from finrl.config import INDICATORS\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
        "from finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "UH81L974WcRe",
        "outputId": "3334dac5-586f-449d-e3af-adee8fbe12bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8cc2edd83354>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_tickers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNAS_100_TICKER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINDICATORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stock_trading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stocktrading_np\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStockTradingEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stock_trading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stock_papertrading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlpacaPaperTrading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'finrl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import gym\n",
        "import numpy as np\n",
        "import numpy.random as rd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "from torch import Tensor\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "class ActorPPO(nn.Module):\n",
        "    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n",
        "        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n",
        "\n",
        "    def forward(self, state: Tensor) -> Tensor:\n",
        "        return self.net(state).tanh()  # action.tanh()\n",
        "\n",
        "    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration\n",
        "        action_avg = self.net(state)\n",
        "        action_std = self.action_std_log.exp()\n",
        "\n",
        "        dist = Normal(action_avg, action_std)\n",
        "        action = dist.sample()\n",
        "        logprob = dist.log_prob(action).sum(1)\n",
        "        return action, logprob\n",
        "\n",
        "    def get_logprob_entropy(self, state: Tensor, action: Tensor) -> (Tensor, Tensor):\n",
        "        action_avg = self.net(state)\n",
        "        action_std = self.action_std_log.exp()\n",
        "\n",
        "        dist = Normal(action_avg, action_std)\n",
        "        logprob = dist.log_prob(action).sum(1)\n",
        "        entropy = dist.entropy().sum(1)\n",
        "        return logprob, entropy\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_action_for_env(action: Tensor) -> Tensor:\n",
        "        return action.tanh()\n",
        "\n",
        "\n",
        "class CriticPPO(nn.Module):\n",
        "    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = build_mlp(dims=[state_dim, *dims, 1])\n",
        "\n",
        "    def forward(self, state: Tensor) -> Tensor:\n",
        "        return self.net(state)  # advantage value\n",
        "\n",
        "\n",
        "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n",
        "    net_list = []\n",
        "    for i in range(len(dims) - 1):\n",
        "        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n",
        "    del net_list[-1]  # remove the activation of output layer\n",
        "    return nn.Sequential(*net_list)\n",
        "\n",
        "\n",
        "class Config:\n",
        "    def __init__(self, agent_class=None, env_class=None, env_args=None):\n",
        "        self.env_class = env_class  # env = env_class(**env_args)\n",
        "        self.env_args = env_args  # env = env_class(**env_args)\n",
        "\n",
        "        if env_args is None:  # dummy env_args\n",
        "            env_args = {'env_name': None, 'state_dim': None, 'action_dim': None, 'if_discrete': None}\n",
        "        self.env_name = env_args['env_name']  # the name of environment. Be used to set 'cwd'.\n",
        "        self.state_dim = env_args['state_dim']  # vector dimension (feature number) of state\n",
        "        self.action_dim = env_args['action_dim']  # vector dimension (feature number) of action\n",
        "        self.if_discrete = env_args['if_discrete']  # discrete or continuous action space\n",
        "\n",
        "        self.agent_class = agent_class  # agent = agent_class(...)\n",
        "\n",
        "        '''Arguments for reward shaping'''\n",
        "        self.gamma = 0.99  # discount factor of future rewards\n",
        "        self.reward_scale = 1.0  # an approximate target reward usually be closed to 256\n",
        "\n",
        "        '''Arguments for training'''\n",
        "        self.gpu_id = int(0)  # `int` means the ID of single GPU, -1 means CPU\n",
        "        self.net_dims = (64, 32)  # the middle layer dimension of MLP (MultiLayer Perceptron)\n",
        "        self.learning_rate = 6e-5  # 2 ** -14 ~= 6e-5\n",
        "        self.soft_update_tau = 5e-3  # 2 ** -8 ~= 5e-3\n",
        "        self.batch_size = int(128)  # num of transitions sampled from replay buffer.\n",
        "        self.horizon_len = int(2000)  # collect horizon_len step while exploring, then update network\n",
        "        self.buffer_size = None  # ReplayBuffer size. Empty the ReplayBuffer for on-policy.\n",
        "        self.repeat_times = 8.0  # repeatedly update network using ReplayBuffer to keep critic's loss small\n",
        "\n",
        "        '''Arguments for evaluate'''\n",
        "        self.cwd = None  # current working directory to save model. None means set automatically\n",
        "        self.break_step = +np.inf  # break training if 'total_step > break_step'\n",
        "        self.eval_times = int(32)  # number of times that get episodic cumulative return\n",
        "        self.eval_per_step = int(2e4)  # evaluate the agent per training steps\n",
        "\n",
        "    def init_before_training(self):\n",
        "        if self.cwd is None:  # set cwd (current working directory) for saving model\n",
        "            self.cwd = f'./{self.env_name}_{self.agent_class.__name__[5:]}'\n",
        "        os.makedirs(self.cwd, exist_ok=True)\n",
        "\n",
        "\n",
        "def get_gym_env_args(env, if_print: bool) -> dict:\n",
        "    if {'unwrapped', 'observation_space', 'action_space', 'spec'}.issubset(dir(env)):  # isinstance(env, gym.Env):\n",
        "        env_name = env.unwrapped.spec.id\n",
        "        state_shape = env.observation_space.shape\n",
        "        state_dim = state_shape[0] if len(state_shape) == 1 else state_shape  # sometimes state_dim is a list\n",
        "\n",
        "        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
        "        if if_discrete:  # make sure it is discrete action space\n",
        "            action_dim = env.action_space.n\n",
        "        elif isinstance(env.action_space, gym.spaces.Box):  # make sure it is continuous action space\n",
        "            action_dim = env.action_space.shape[0]\n",
        "\n",
        "    env_args = {'env_name': env_name, 'state_dim': state_dim, 'action_dim': action_dim, 'if_discrete': if_discrete}\n",
        "    print(f\"env_args = {repr(env_args)}\") if if_print else None\n",
        "    return env_args\n",
        "\n",
        "\n",
        "def kwargs_filter(function, kwargs: dict) -> dict:\n",
        "    import inspect\n",
        "    sign = inspect.signature(function).parameters.values()\n",
        "    sign = {val.name for val in sign}\n",
        "    common_args = sign.intersection(kwargs.keys())\n",
        "    return {key: kwargs[key] for key in common_args}  # filtered kwargs\n",
        "\n",
        "\n",
        "def build_env(env_class=None, env_args=None):\n",
        "    if env_class.__module__ == 'gym.envs.registration':  # special rule\n",
        "        env = env_class(id=env_args['env_name'])\n",
        "    else:\n",
        "        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n",
        "    for attr_str in ('env_name', 'state_dim', 'action_dim', 'if_discrete'):\n",
        "        setattr(env, attr_str, env_args[attr_str])\n",
        "    return env\n",
        "\n",
        "\n",
        "class AgentBase:\n",
        "    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "        self.gamma = args.gamma\n",
        "        self.batch_size = args.batch_size\n",
        "        self.repeat_times = args.repeat_times\n",
        "        self.reward_scale = args.reward_scale\n",
        "        self.soft_update_tau = args.soft_update_tau\n",
        "\n",
        "        self.states = None  # assert self.states == (1, state_dim)\n",
        "        self.device = torch.device(f\"cuda:{gpu_id}\" if (torch.cuda.is_available() and (gpu_id >= 0)) else \"cpu\")\n",
        "\n",
        "        act_class = getattr(self, \"act_class\", None)\n",
        "        cri_class = getattr(self, \"cri_class\", None)\n",
        "        self.act = self.act_target = act_class(net_dims, state_dim, action_dim).to(self.device)\n",
        "        self.cri = self.cri_target = cri_class(net_dims, state_dim, action_dim).to(self.device) \\\n",
        "            if cri_class else self.act\n",
        "\n",
        "        self.act_optimizer = torch.optim.Adam(self.act.parameters(), args.learning_rate)\n",
        "        self.cri_optimizer = torch.optim.Adam(self.cri.parameters(), args.learning_rate) \\\n",
        "            if cri_class else self.act_optimizer\n",
        "\n",
        "        self.criterion = torch.nn.SmoothL1Loss()\n",
        "\n",
        "    @staticmethod\n",
        "    def optimizer_update(optimizer, objective: Tensor):\n",
        "        optimizer.zero_grad()\n",
        "        objective.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    @staticmethod\n",
        "    def soft_update(target_net: torch.nn.Module, current_net: torch.nn.Module, tau: float):\n",
        "        for tar, cur in zip(target_net.parameters(), current_net.parameters()):\n",
        "            tar.data.copy_(cur.data * tau + tar.data * (1.0 - tau))\n",
        "\n",
        "\n",
        "class AgentPPO(AgentBase):\n",
        "    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n",
        "        self.if_off_policy = False\n",
        "        self.act_class = getattr(self, \"act_class\", ActorPPO)\n",
        "        self.cri_class = getattr(self, \"cri_class\", CriticPPO)\n",
        "        AgentBase.__init__(self, net_dims, state_dim, action_dim, gpu_id, args)\n",
        "\n",
        "        self.ratio_clip = getattr(args, \"ratio_clip\", 0.25)  # `ratio.clamp(1 - clip, 1 + clip)`\n",
        "        self.lambda_gae_adv = getattr(args, \"lambda_gae_adv\", 0.95)  # could be 0.80~0.99\n",
        "        self.lambda_entropy = getattr(args, \"lambda_entropy\", 0.01)  # could be 0.00~0.10\n",
        "        self.lambda_entropy = torch.tensor(self.lambda_entropy, dtype=torch.float32, device=self.device)\n",
        "\n",
        "    def explore_env(self, env, horizon_len: int) -> [Tensor]:\n",
        "        states = torch.zeros((horizon_len, self.state_dim), dtype=torch.float32).to(self.device)\n",
        "        actions = torch.zeros((horizon_len, self.action_dim), dtype=torch.float32).to(self.device)\n",
        "        logprobs = torch.zeros(horizon_len, dtype=torch.float32).to(self.device)\n",
        "        rewards = torch.zeros(horizon_len, dtype=torch.float32).to(self.device)\n",
        "        dones = torch.zeros(horizon_len, dtype=torch.bool).to(self.device)\n",
        "\n",
        "        ary_state = self.states[0]\n",
        "\n",
        "        get_action = self.act.get_action\n",
        "        convert = self.act.convert_action_for_env\n",
        "        for i in range(horizon_len):\n",
        "            state = torch.as_tensor(ary_state, dtype=torch.float32, device=self.device)\n",
        "            action, logprob = [t.squeeze(0) for t in get_action(state.unsqueeze(0))[:2]]\n",
        "\n",
        "            ary_action = convert(action).detach().cpu().numpy()\n",
        "            ary_state, reward, done, _ = env.step(ary_action)\n",
        "            if done:\n",
        "                ary_state = env.reset()\n",
        "\n",
        "            states[i] = state\n",
        "            actions[i] = action\n",
        "            logprobs[i] = logprob\n",
        "            rewards[i] = reward\n",
        "            dones[i] = done\n",
        "\n",
        "        self.states[0] = ary_state\n",
        "        rewards = (rewards * self.reward_scale).unsqueeze(1)\n",
        "        undones = (1 - dones.type(torch.float32)).unsqueeze(1)\n",
        "        return states, actions, logprobs, rewards, undones\n",
        "\n",
        "    def update_net(self, buffer) -> [float]:\n",
        "        with torch.no_grad():\n",
        "            states, actions, logprobs, rewards, undones = buffer\n",
        "            buffer_size = states.shape[0]\n",
        "\n",
        "            '''get advantages reward_sums'''\n",
        "            bs = 2 ** 10  # set a smaller 'batch_size' when out of GPU memory.\n",
        "            values = [self.cri(states[i:i + bs]) for i in range(0, buffer_size, bs)]\n",
        "            values = torch.cat(values, dim=0).squeeze(1)  # values.shape == (buffer_size, )\n",
        "\n",
        "            advantages = self.get_advantages(rewards, undones, values)  # advantages.shape == (buffer_size, )\n",
        "            reward_sums = advantages + values  # reward_sums.shape == (buffer_size, )\n",
        "            del rewards, undones, values\n",
        "\n",
        "            advantages = (advantages - advantages.mean()) / (advantages.std(dim=0) + 1e-5)\n",
        "        assert logprobs.shape == advantages.shape == reward_sums.shape == (buffer_size,)\n",
        "\n",
        "        '''update network'''\n",
        "        obj_critics = 0.0\n",
        "        obj_actors = 0.0\n",
        "\n",
        "        update_times = int(buffer_size * self.repeat_times / self.batch_size)\n",
        "        assert update_times >= 1\n",
        "        for _ in range(update_times):\n",
        "            indices = torch.randint(buffer_size, size=(self.batch_size,), requires_grad=False)\n",
        "            state = states[indices]\n",
        "            action = actions[indices]\n",
        "            logprob = logprobs[indices]\n",
        "            advantage = advantages[indices]\n",
        "            reward_sum = reward_sums[indices]\n",
        "\n",
        "            value = self.cri(state).squeeze(1)  # critic network predicts the reward_sum (Q value) of state\n",
        "            obj_critic = self.criterion(value, reward_sum)\n",
        "            self.optimizer_update(self.cri_optimizer, obj_critic)\n",
        "\n",
        "            new_logprob, obj_entropy = self.act.get_logprob_entropy(state, action)\n",
        "            ratio = (new_logprob - logprob.detach()).exp()\n",
        "            surrogate1 = advantage * ratio\n",
        "            surrogate2 = advantage * ratio.clamp(1 - self.ratio_clip, 1 + self.ratio_clip)\n",
        "            obj_surrogate = torch.min(surrogate1, surrogate2).mean()\n",
        "\n",
        "            obj_actor = obj_surrogate + obj_entropy.mean() * self.lambda_entropy\n",
        "            self.optimizer_update(self.act_optimizer, -obj_actor)\n",
        "\n",
        "            obj_critics += obj_critic.item()\n",
        "            obj_actors += obj_actor.item()\n",
        "        a_std_log = getattr(self.act, 'a_std_log', torch.zeros(1)).mean()\n",
        "        return obj_critics / update_times, obj_actors / update_times, a_std_log.item()\n",
        "\n",
        "    def get_advantages(self, rewards: Tensor, undones: Tensor, values: Tensor) -> Tensor:\n",
        "        advantages = torch.empty_like(values)  # advantage value\n",
        "\n",
        "        masks = undones * self.gamma\n",
        "        horizon_len = rewards.shape[0]\n",
        "\n",
        "        next_state = torch.tensor(self.states, dtype=torch.float32).to(self.device)\n",
        "        next_value = self.cri(next_state).detach()[0, 0]\n",
        "\n",
        "        advantage = 0  # last_gae_lambda\n",
        "        for t in range(horizon_len - 1, -1, -1):\n",
        "            delta = rewards[t] + masks[t] * next_value - values[t]\n",
        "            advantages[t] = advantage = delta + masks[t] * self.lambda_gae_adv * advantage\n",
        "            next_value = values[t]\n",
        "        return advantages\n",
        "\n",
        "\n",
        "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n",
        "    def __init__(self):\n",
        "        gym.logger.set_level(40)  # Block warning\n",
        "        gym_env_name = \"Pendulum-v0\" if gym.__version__ < '0.18.0' else \"Pendulum-v1\"\n",
        "        super().__init__(env=gym.make(gym_env_name))\n",
        "\n",
        "        '''the necessary env information when you design a custom env'''\n",
        "        self.env_name = gym_env_name  # the name of this env.\n",
        "        self.state_dim = self.observation_space.shape[0]  # feature number of state\n",
        "        self.action_dim = self.action_space.shape[0]  # feature number of action\n",
        "        self.if_discrete = False  # discrete action or continuous action\n",
        "\n",
        "    def reset(self) -> np.ndarray:  # reset the agent in env\n",
        "        return self.env.reset()\n",
        "\n",
        "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):  # agent interacts in env\n",
        "        # We suggest that adjust action space to (-1, +1) when designing a custom env.\n",
        "        state, reward, done, info_dict = self.env.step(action * 2)\n",
        "        return state.reshape(self.state_dim), float(reward), done, info_dict\n",
        "\n",
        "    \n",
        "def train_agent(args: Config):\n",
        "    args.init_before_training()\n",
        "\n",
        "    env = build_env(args.env_class, args.env_args)\n",
        "    agent = args.agent_class(args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args)\n",
        "    agent.states = env.reset()[np.newaxis, :]\n",
        "\n",
        "    evaluator = Evaluator(eval_env=build_env(args.env_class, args.env_args),\n",
        "                          eval_per_step=args.eval_per_step,\n",
        "                          eval_times=args.eval_times,\n",
        "                          cwd=args.cwd)\n",
        "    torch.set_grad_enabled(False)\n",
        "    while True: # start training\n",
        "        buffer_items = agent.explore_env(env, args.horizon_len)\n",
        "\n",
        "        torch.set_grad_enabled(True)\n",
        "        logging_tuple = agent.update_net(buffer_items)\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "        evaluator.evaluate_and_save(agent.act, args.horizon_len, logging_tuple)\n",
        "        if (evaluator.total_step > args.break_step) or os.path.exists(f\"{args.cwd}/stop\"):\n",
        "            torch.save(agent.act.state_dict(), args.cwd + '/actor.pth')\n",
        "            break  # stop training when reach `break_step` or `mkdir cwd/stop`\n",
        "\n",
        "\n",
        "def render_agent(env_class, env_args: dict, net_dims: [int], agent_class, actor_path: str, render_times: int = 8):\n",
        "    env = build_env(env_class, env_args)\n",
        "\n",
        "    state_dim = env_args['state_dim']\n",
        "    action_dim = env_args['action_dim']\n",
        "    agent = agent_class(net_dims, state_dim, action_dim, gpu_id=-1)\n",
        "    actor = agent.act\n",
        "\n",
        "    print(f\"| render and load actor from: {actor_path}\")\n",
        "    actor.load_state_dict(torch.load(actor_path, map_location=lambda storage, loc: storage))\n",
        "    for i in range(render_times):\n",
        "        cumulative_reward, episode_step = get_rewards_and_steps(env, actor, if_render=True)\n",
        "        print(f\"|{i:4}  cumulative_reward {cumulative_reward:9.3f}  episode_step {episode_step:5.0f}\")\n",
        "\n",
        "        \n",
        "class Evaluator:\n",
        "    def __init__(self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = '.'):\n",
        "        self.cwd = cwd\n",
        "        self.env_eval = eval_env\n",
        "        self.eval_step = 0\n",
        "        self.total_step = 0\n",
        "        self.start_time = time.time()\n",
        "        self.eval_times = eval_times  # number of times that get episodic cumulative return\n",
        "        self.eval_per_step = eval_per_step  # evaluate the agent per training steps\n",
        "\n",
        "        self.recorder = []\n",
        "        print(f\"\\n| `step`: Number of samples, or total training steps, or running times of `env.step()`.\"\n",
        "              f\"\\n| `time`: Time spent from the start of training to this moment.\"\n",
        "              f\"\\n| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.\"\n",
        "              f\"\\n| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.\"\n",
        "              f\"\\n| `avgS`: Average of steps in an episode.\"\n",
        "              f\"\\n| `objC`: Objective of Critic network. Or call it loss function of critic network.\"\n",
        "              f\"\\n| `objA`: Objective of Actor network. It is the average Q value of the critic network.\"\n",
        "              f\"\\n| {'step':>8}  {'time':>8}  | {'avgR':>8}  {'stdR':>6}  {'avgS':>6}  | {'objC':>8}  {'objA':>8}\")\n",
        "            \n",
        "    def evaluate_and_save(self, actor, horizon_len: int, logging_tuple: tuple):\n",
        "        self.total_step += horizon_len\n",
        "        if self.eval_step + self.eval_per_step > self.total_step:\n",
        "            return\n",
        "        self.eval_step = self.total_step\n",
        "\n",
        "        rewards_steps_ary = [get_rewards_and_steps(self.env_eval, actor) for _ in range(self.eval_times)]\n",
        "        rewards_steps_ary = np.array(rewards_steps_ary, dtype=np.float32)\n",
        "        avg_r = rewards_steps_ary[:, 0].mean()  # average of cumulative rewards\n",
        "        std_r = rewards_steps_ary[:, 0].std()  # std of cumulative rewards\n",
        "        avg_s = rewards_steps_ary[:, 1].mean()  # average of steps in an episode\n",
        "\n",
        "        used_time = time.time() - self.start_time\n",
        "        self.recorder.append((self.total_step, used_time, avg_r))\n",
        "        \n",
        "        print(f\"| {self.total_step:8.2e}  {used_time:8.0f}  \"\n",
        "              f\"| {avg_r:8.2f}  {std_r:6.2f}  {avg_s:6.0f}  \"\n",
        "              f\"| {logging_tuple[0]:8.2f}  {logging_tuple[1]:8.2f}\")\n",
        "\n",
        "\n",
        "def get_rewards_and_steps(env, actor, if_render: bool = False) -> (float, int):  # cumulative_rewards and episode_steps\n",
        "    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n",
        "\n",
        "    state = env.reset()\n",
        "    episode_steps = 0\n",
        "    cumulative_returns = 0.0  # sum of rewards in an episode\n",
        "    for episode_steps in range(12345):\n",
        "        tensor_state = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "        tensor_action = actor(tensor_state)\n",
        "        action = tensor_action.detach().cpu().numpy()[0]  # not need detach(), because using torch.no_grad() outside\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        cumulative_returns += reward\n",
        "\n",
        "        if if_render:\n",
        "            env.render()\n",
        "        if done:\n",
        "            break\n",
        "    return cumulative_returns, episode_steps + 1"
      ],
      "metadata": {
        "id": "XDgnczzAU_JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "# from elegantrl.agents import AgentA2C\n",
        "\n",
        "MODELS = {\"ppo\": AgentPPO}\n",
        "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\n",
        "ON_POLICY_MODELS = [\"ppo\"]\n",
        "# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n",
        "#\n",
        "# NOISE = {\n",
        "#     \"normal\": NormalActionNoise,\n",
        "#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n",
        "# }\n",
        "\n",
        "\n",
        "class DRLAgent:\n",
        "    \"\"\"Implementations of DRL algorithms\n",
        "    Attributes\n",
        "    ----------\n",
        "        env: gym environment class\n",
        "            user-defined class\n",
        "    Methods\n",
        "    -------\n",
        "        get_model()\n",
        "            setup DRL algorithms\n",
        "        train_model()\n",
        "            train DRL algorithms in a train dataset\n",
        "            and output the trained model\n",
        "        DRL_prediction()\n",
        "            make a prediction in a test dataset and get results\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env, price_array, tech_array, turbulence_array):\n",
        "        self.env = env\n",
        "        self.price_array = price_array\n",
        "        self.tech_array = tech_array\n",
        "        self.turbulence_array = turbulence_array\n",
        "\n",
        "    def get_model(self, model_name, model_kwargs):\n",
        "        env_config = {\n",
        "            \"price_array\": self.price_array,\n",
        "            \"tech_array\": self.tech_array,\n",
        "            \"turbulence_array\": self.turbulence_array,\n",
        "            \"if_train\": True,\n",
        "        }\n",
        "        environment = self.env(config=env_config)\n",
        "        env_args = {'config': env_config,\n",
        "              'env_name': environment.env_name,\n",
        "              'state_dim': environment.state_dim,\n",
        "              'action_dim': environment.action_dim,\n",
        "              'if_discrete': False}\n",
        "        agent = MODELS[model_name]\n",
        "        if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "        model = Config(agent_class=agent, env_class=self.env, env_args=env_args)\n",
        "        model.if_off_policy = model_name in OFF_POLICY_MODELS\n",
        "        if model_kwargs is not None:\n",
        "            try:\n",
        "                model.learning_rate = model_kwargs[\"learning_rate\"]\n",
        "                model.batch_size = model_kwargs[\"batch_size\"]\n",
        "                model.gamma = model_kwargs[\"gamma\"]\n",
        "                model.seed = model_kwargs[\"seed\"]\n",
        "                model.net_dims = model_kwargs[\"net_dimension\"]\n",
        "                model.target_step = model_kwargs[\"target_step\"]\n",
        "                model.eval_gap = model_kwargs[\"eval_gap\"]\n",
        "                model.eval_times = model_kwargs[\"eval_times\"]\n",
        "            except BaseException:\n",
        "                raise ValueError(\n",
        "                    \"Fail to read arguments, please check 'model_kwargs' input.\"\n",
        "                )\n",
        "        return model\n",
        "\n",
        "    def train_model(self, model, cwd, total_timesteps=5000):\n",
        "        model.cwd = cwd\n",
        "        model.break_step = total_timesteps\n",
        "        train_agent(model)\n",
        "\n",
        "    @staticmethod\n",
        "    def DRL_prediction(model_name, cwd, net_dimension, environment):\n",
        "        if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "        agent_class = MODELS[model_name]\n",
        "        environment.env_num = 1\n",
        "        agent = agent_class(net_dimension, environment.state_dim, environment.action_dim)\n",
        "        actor = agent.act\n",
        "        # load agent\n",
        "        try:  \n",
        "            cwd = cwd + '/actor.pth'\n",
        "            print(f\"| load actor from: {cwd}\")\n",
        "            actor.load_state_dict(torch.load(cwd, map_location=lambda storage, loc: storage))\n",
        "            act = actor\n",
        "            device = agent.device\n",
        "        except BaseException:\n",
        "            raise ValueError(\"Fail to load agent!\")\n",
        "\n",
        "        # test on the testing env\n",
        "        _torch = torch\n",
        "        state = environment.reset()\n",
        "        episode_returns = []  # the cumulative_return / initial_account\n",
        "        episode_total_assets = [environment.initial_total_asset]\n",
        "        with _torch.no_grad():\n",
        "            for i in range(environment.max_step):\n",
        "                s_tensor = _torch.as_tensor((state,), device=device)\n",
        "                a_tensor = act(s_tensor)  # action_tanh = act.forward()\n",
        "                action = (\n",
        "                    a_tensor.detach().cpu().numpy()[0]\n",
        "                )  # not need detach(), because with torch.no_grad() outside\n",
        "                state, reward, done, _ = environment.step(action)\n",
        "\n",
        "                total_asset = (\n",
        "                    environment.amount\n",
        "                    + (\n",
        "                        environment.price_ary[environment.day] * environment.stocks\n",
        "                    ).sum()\n",
        "                )\n",
        "                episode_total_assets.append(total_asset)\n",
        "                episode_return = total_asset / environment.initial_total_asset\n",
        "                episode_returns.append(episode_return)\n",
        "                if done:\n",
        "                    break\n",
        "        print(\"Test Finished!\")\n",
        "        # return episode total_assets on testing data\n",
        "        print(\"episode_return\", episode_return)\n",
        "        return episode_total_assets"
      ],
      "metadata": {
        "id": "TSUbY5rlVYdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from finrl.config import ERL_PARAMS\n",
        "from finrl.config import INDICATORS\n",
        "from finrl.config import RLlib_PARAMS\n",
        "from finrl.config import SAC_PARAMS\n",
        "from finrl.config import TRAIN_END_DATE\n",
        "from finrl.config import TRAIN_START_DATE\n",
        "from finrl.config_tickers import NAS_100_TICKER\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "# construct environment\n",
        "\n",
        "\n",
        "def train(\n",
        "    start_date,\n",
        "    end_date,\n",
        "    ticker_list,\n",
        "    data_source,\n",
        "    time_interval,\n",
        "    technical_indicator_list,\n",
        "    drl_lib,\n",
        "    env,\n",
        "    model_name,\n",
        "    if_vix=True,\n",
        "    **kwargs,\n",
        "):\n",
        "    # download data\n",
        "    dp = DataProcessor(data_source, **kwargs)\n",
        "    data = dp.download_data(ticker_list, start_date, end_date, time_interval)\n",
        "    data = dp.clean_data(data)\n",
        "    data = dp.add_technical_indicator(data, technical_indicator_list)\n",
        "    if if_vix:\n",
        "        data = dp.add_vix(data)\n",
        "    else:\n",
        "        data = dp.add_turbulence(data)\n",
        "    price_array, tech_array, turbulence_array = dp.df_to_array(data, if_vix)\n",
        "    env_config = {\n",
        "        \"price_array\": price_array,\n",
        "        \"tech_array\": tech_array,\n",
        "        \"turbulence_array\": turbulence_array,\n",
        "        \"if_train\": True,\n",
        "    }\n",
        "    env_instance = env(config=env_config)\n",
        "\n",
        "    # read parameters\n",
        "    cwd = kwargs.get(\"cwd\", \"./\" + str(model_name))\n",
        "\n",
        "    if drl_lib == \"elegantrl\":\n",
        "        DRLAgent_erl = DRLAgent\n",
        "        break_step = kwargs.get(\"break_step\", 1e6)\n",
        "        erl_params = kwargs.get(\"erl_params\")\n",
        "        agent = DRLAgent_erl(\n",
        "            env=env,\n",
        "            price_array=price_array,\n",
        "            tech_array=tech_array,\n",
        "            turbulence_array=turbulence_array,\n",
        "        )\n",
        "        model = agent.get_model(model_name, model_kwargs=erl_params)\n",
        "        trained_model = agent.train_model(\n",
        "            model=model, cwd=cwd, total_timesteps=break_step\n",
        "        )"
      ],
      "metadata": {
        "id": "AbiE2vjEVbdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from finrl.config import INDICATORS\n",
        "from finrl.config import RLlib_PARAMS\n",
        "from finrl.config import TEST_END_DATE\n",
        "from finrl.config import TEST_START_DATE\n",
        "from finrl.config_tickers import NAS_100_TICKER\n",
        "\n",
        "def test(\n",
        "    start_date,\n",
        "    end_date,\n",
        "    ticker_list,\n",
        "    data_source,\n",
        "    time_interval,\n",
        "    technical_indicator_list,\n",
        "    drl_lib,\n",
        "    env,\n",
        "    model_name,\n",
        "    if_vix=True,\n",
        "    **kwargs,\n",
        "):\n",
        "\n",
        "    # import data processor\n",
        "    from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "    # fetch data\n",
        "    dp = DataProcessor(data_source, **kwargs)\n",
        "    data = dp.download_data(ticker_list, start_date, end_date, time_interval)\n",
        "    data = dp.clean_data(data)\n",
        "    data = dp.add_technical_indicator(data, technical_indicator_list)\n",
        "\n",
        "    if if_vix:\n",
        "        data = dp.add_vix(data)\n",
        "    else:\n",
        "        data = dp.add_turbulence(data)\n",
        "    price_array, tech_array, turbulence_array = dp.df_to_array(data, if_vix)\n",
        "\n",
        "    env_config = {\n",
        "        \"price_array\": price_array,\n",
        "        \"tech_array\": tech_array,\n",
        "        \"turbulence_array\": turbulence_array,\n",
        "        \"if_train\": False,\n",
        "    }\n",
        "    env_instance = env(config=env_config)\n",
        "\n",
        "    # load elegantrl needs state dim, action dim and net dim\n",
        "    net_dimension = kwargs.get(\"net_dimension\", 2**7)\n",
        "    cwd = kwargs.get(\"cwd\", \"./\" + str(model_name))\n",
        "    print(\"price_array: \", len(price_array))\n",
        "\n",
        "    if drl_lib == \"elegantrl\":\n",
        "        DRLAgent_erl = DRLAgent\n",
        "        episode_total_assets = DRLAgent_erl.DRL_prediction(\n",
        "            model_name=model_name,\n",
        "            cwd=cwd,\n",
        "            net_dimension=net_dimension,\n",
        "            environment=env_instance,\n",
        "        )\n",
        "        return episode_total_assets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "9gSsAjBYV85y",
        "outputId": "0eab72cd-c745-437a-8726-faebf84b2691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-43e1c9d5f51b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINDICATORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRLlib_PARAMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTEST_END_DATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'finrl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_list = NAS_100_TICKER\n",
        "action_dim = len(NAS_100_TICKER)"
      ],
      "metadata": {
        "id": "TVCa14OIWDtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ticker_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2K0_8TfWOZD",
        "outputId": "059286ec-e487-45f4-dc23-cb3dd4dfda51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AMGN', 'AAPL', 'AMAT', 'INTC', 'PCAR', 'PAYX', 'MSFT', 'ADBE', 'CSCO', 'XLNX', 'QCOM', 'COST', 'SBUX', 'FISV', 'CTXS', 'INTU', 'AMZN', 'EBAY', 'BIIB', 'CHKP', 'GILD', 'NLOK', 'CMCSA', 'FAST', 'ADSK', 'CTSH', 'NVDA', 'GOOGL', 'ISRG', 'VRTX', 'HSIC', 'BIDU', 'ATVI', 'ADP', 'ROST', 'ORLY', 'CERN', 'BKNG', 'MYL', 'MU', 'DLTR', 'ALXN', 'SIRI', 'MNST', 'AVGO', 'TXN', 'MDLZ', 'FB', 'ADI', 'WDC', 'REGN', 'LBTYK', 'VRSK', 'NFLX', 'TSLA', 'CHTR', 'MAR', 'ILMN', 'LRCX', 'EA', 'AAL', 'WBA', 'KHC', 'BMRN', 'JD', 'SWKS', 'INCY', 'PYPL', 'CDW', 'FOXA', 'MXIM', 'TMUS', 'EXPE', 'TCOM', 'ULTA', 'CSX', 'NTES', 'MCHP', 'CTAS', 'KLAC', 'HAS', 'JBHT', 'IDXX', 'WYNN', 'MELI', 'ALGN', 'CDNS', 'WDAY', 'SNPS', 'ASML', 'TTWO', 'PEP', 'NXPI', 'XEL', 'AMD', 'NTAP', 'VRSN', 'LULU', 'WLTW', 'UAL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(INDICATORS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgo29eUIWZo2",
        "outputId": "7a7f0229-18d4-4e16-8c31-4a5578f4ed64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = StockTradingEnv"
      ],
      "metadata": {
        "id": "UWVya4CkWgIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DP = DataProcessor(data_source = 'alpaca',\n",
        "                  API_KEY = \"PK77D8FGOW608O2G0Y93\", \n",
        "                  API_SECRET = \"ppOn9d5ce1g9pipqfwAp16ruRdzjzvZOWflMapVp\", \n",
        "                  API_BASE_URL = 'https://paper-api.alpaca.markets'\n",
        "                  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Fn_petrVWlA_",
        "outputId": "88eb4e43-484e-467e-e71a-b22be4b48c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8f4c0d8a6453>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m DP = DataProcessor(data_source = 'alpaca',\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mAPI_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"PK77D8FGOW608O2G0Y93\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mAPI_SECRET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ppOn9d5ce1g9pipqfwAp16ruRdzjzvZOWflMapVp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mAPI_BASE_URL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://paper-api.alpaca.markets'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataProcessor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = DP.download_data(start_date = '2023-04-17', \n",
        "                        end_date = '2023-04-21',\n",
        "                        ticker_list = NAS_100_TICKER,\n",
        "                        time_interval= '1Min')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "eqTI0QTSXlGr",
        "outputId": "1692abca-c3e1-4e9a-c3a9-27495ffe69ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-219c156ee95a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data = DP.download_data(start_date = '2023-04-17', \n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2023-04-21'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mticker_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNAS_100_TICKER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         time_interval= '1Min')\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/finrl/meta/data_processor.py\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(self, ticker_list, start_date, end_date, time_interval)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     ) -> pd.DataFrame:\n\u001b[0;32m---> 37\u001b[0;31m         df = self.processor.download_data(\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mticker_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mticker_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/finrl/meta/data_processors/processor_alpaca.py\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(self, ticker_list, start_date, end_date, time_interval)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# filter opening time of the New York Stock Exchange (NYSE) (from 9:30 am to 4:00 pm) if time_interval < 1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mday_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m86400000000000\u001b[0m  \u001b[0;31m# pd.Timedelta('1D').delta == 86400000000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mday_delta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mNYSE_open_hour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"14:30\"\u001b[0m  \u001b[0;31m# in UTC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mNYSE_close_hour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"20:59\"\u001b[0m  \u001b[0;31m# in UTC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Timedelta' object has no attribute 'delta'"
          ]
        }
      ]
    }
  ]
}